{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417c9f09-9c95-40f3-8347-bdd777477955",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sparkify Project Workspace AWS - Full Dataset (12GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941ebb3-3c2a-4514-857d-109f0b4940a7",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Sparkify is a popular (not real!) music service** similar to Spotify or Pandora with a **subscription-based business model**. Each user can listen to their favorite music every day either through the **free-tier** that inserts advertisements between songs or by using a **subscription plan where you pay a fixed monthly fee**. Users can **upgrade, downgrade, or cancel the service at any time**, so it's critical to be sure users love the service. \n",
    "\n",
    "**Every time a user interacts with the service it generates (synthetic) data**. Each event (e.g., song played, logout, like, downgrade, ...) is recorded with the corresponding timestamp. All of this information holds the key to keeping users happy and business thriving.\n",
    "\n",
    "Our **goal** is to answer the following question:<br>\n",
    "\n",
    "**Which users are at risk of churn, i.e. downgrade from premium service to free-tier plan or cancellation of service altogether?**\n",
    "\n",
    "By **identifying** these **users before they abandon the service**, we can **proactively engage with them** by offering some discounts and/or incentives, **saving a lot of money** from a business perspective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8551dd-bc4c-4d6e-93d6-3395c7aaa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome to my EMR Notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977f180-ea3c-4174-9baa-46f1fc5e0aa3",
   "metadata": {},
   "source": [
    "## Installing Missing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882c6a6-1241-4516-945f-f994dce4df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.install_pypi_package(\"Cython\")\n",
    "sc.install_pypi_package(\"pandas==1.0.5\")\n",
    "sc.install_pypi_package(\"matplotlib==3.2.2\", \"https://pypi.org/simple\")\n",
    "sc.install_pypi_package(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725480e-71e8-4c1b-9323-5af26f8c2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0d7cd-a8ec-4b6c-8f92-c4f9cf53bcb2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577b3e9-3b8a-4d7a-b7a6-c25eac48e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, StringType, DateType\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, NaiveBayes, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Normalizer, StandardScaler, MinMaxScaler, IndexToString\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96744bc9-8ed7-47fe-9ded-ba76d827f730",
   "metadata": {},
   "source": [
    "## Create a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fad23-06c9-46ae-a020-a27dcea7ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be32317-6128-4092-849f-e2801b285ba8",
   "metadata": {},
   "source": [
    "## Import data from S3 Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265ca1a-28aa-423d-a39e-090fd974f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n",
    "df = spark.read.json(event_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15e97c-0f9c-494c-8eca-28828fbeea36",
   "metadata": {},
   "source": [
    "## Explore and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcb42a-4890-4765-bf1e-16cb19faf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9d409-1d44-40af-9b8d-b61e3353328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe shape\n",
    "print(f'The dataset at hand contains {df.count()} events and {len(df.columns)} features recorded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda2414-1bae-457a-8cbf-ade7751bcd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb7f7d-2db3-4d7e-9d70-e46284af5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_users = df.select(F.countDistinct('userId')).show()\n",
    "\n",
    "print(f'There are {num_unique_users} unique users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bf95d-77d4-49aa-936f-7b46491f1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "\n",
    "def count_missing(df, col):\n",
    "    \"\"\"\n",
    "    Function that counts missing values (nan, null, empty) in a column of the dataset.\n",
    "    \"\"\"\n",
    "    return df.filter((isnan(df[col])) | (df[col].isNull()) | (df[col] == \"\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3188b78-386b-4d2b-9455-e56d8f947353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    missing_count = count_missing(df, col)\n",
    "    if missing_count > 0:\n",
    "        print(f\"{col}: {missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b3d41-15f2-49c6-988b-ca7844a81469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    Function that performs data cleaning of Sparkify dataset.\n",
    "    \n",
    "    INPUT: \n",
    "    df - pyspark dataframe containing Sparkify events\n",
    "    \n",
    "    OUTPUT:\n",
    "    df_new - pyspark dataframe with removed rows with empty 'userId' column and duplicates if any\n",
    "    '''\n",
    "    \n",
    "    # remove rows where userId is empty and duplicated rows\n",
    "    df_clean = df.filter(df[\"userId\"] != \"\").dropDuplicates()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def get_date_from_timestamp(df, col_name, new_col_name):\n",
    "    '''\n",
    "    Function that convert timestamp to date\n",
    "    '''\n",
    "    \n",
    "    return df.withColumn(new_col_name, F.to_timestamp(F.col(col_name) / 1000).astype(StringType()))\n",
    "\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    '''\n",
    "    Function for preparation of dataset for machine learning models.\n",
    "    \n",
    "    INPUT:\n",
    "    df - initial dataset loaded from json file\n",
    "    \n",
    "    OUTPUT:\n",
    "    df_ml - new dataset prepared for machine learning which\n",
    "    contains the following columns:\n",
    "    \n",
    "    1. userId - initial id of the user\n",
    "    2. gender - user's gender\n",
    "    3. days_registered - days since user's registration\n",
    "    4. avg_events_per_day - average number of events per day for the user\n",
    "    5. avg_session_lenght - average lenght of session per user\n",
    "    6. thumbs_up - number of thumbs up events\n",
    "    7. thumbs_down - number of thumbs down events\n",
    "    8. addfriends - number of add friends events\n",
    "    9. addplaylist - number of add to playlist events\n",
    "    '''\n",
    "    \n",
    "    # Clean dataset using clean_data function\n",
    "    df = clean_data(df)\n",
    "    \n",
    "    # Convert event timestamp\n",
    "    df = get_date_from_timestamp(df, 'ts', 'ts_date')\n",
    "    \n",
    "    # Convert registration timestamp\n",
    "    df = get_date_from_timestamp(df, 'registration', 'registration_date')\n",
    "    \n",
    "    # Create column Churn when the event recorded is 'Cancellation Confirmation'. \n",
    "    # A value equal to 1 indicates that the user cancelled the subscription.\n",
    "    churn_cancellation = udf(lambda x: 1 if x==\"Cancellation Confirmation\" else 0, IntegerType())\n",
    "    \n",
    "    df = df.withColumn(\"churn_cancellation\", churn_cancellation(\"page\"))\n",
    "    \n",
    "    # Get userId with churn_cancellation == 1\n",
    "    cancelled_users = df.select(['userId']).where(df.churn_cancellation == 1).groupby('userId').count().toPandas()['userId'].values\n",
    "    cancelled_users = list(cancelled_users)\n",
    "    df = df.withColumn('churn_cancellation', when((df.userId).isin(cancelled_users), 1).otherwise(0))\n",
    "    \n",
    "    # Convert column gender to numeric: 1 for 'female' and 0 for 'male'\n",
    "    gender = udf(lambda x: 1 if x==\"F\" else 0, IntegerType())\n",
    "    \n",
    "    df = df.withColumn(\"gender\", gender(\"gender\"))\n",
    "    \n",
    "    # Convert column level to numeric: 1 for 'paid' and 0 for 'free'\n",
    "    level = udf(lambda x: 1 if x==\"paid\" else 0, IntegerType())\n",
    "    \n",
    "    #df = df.withColumn(\"level\", level(\"level\"))\n",
    "    \n",
    "    levels = df.select(['userId', 'level', 'ts_date'])\\\n",
    "                        .orderBy(desc('ts_date'))\\\n",
    "                        .dropDuplicates(['userId'])\\\n",
    "                        .select(['userId', 'level'])\\\n",
    "                        .withColumn('last_level', level('level').cast(IntegerType()))\n",
    "    levels = levels.drop('level')\n",
    "    levels = levels.withColumnRenamed('userId', 'level_userId')\n",
    "\n",
    "    \n",
    "    # Compute active days as number of days since registration\n",
    "    # Create dataframe with last timestamp (ts_date) per user\n",
    "    df_last_ts = df.groupBy('userId').agg(max('ts_date').alias('last_interaction'))\n",
    "    \n",
    "    # Join dataframes and add column 'days_registered' with number of days from registration date to ts for last event\n",
    "    df = df.join(df_last_ts, on='userId').select(df_last_ts['*'], df['*']).withColumn('days_registered', datediff(df_last_ts['last_interaction'], df['registration_date']).cast('float'))\n",
    "    \n",
    "    # Create a new column 'date' with format 'yyyy-MM-dd'\n",
    "    df = df.withColumn('date', date_format('ts_date', 'yyyy-MM-dd').alias('date'))\n",
    "    \n",
    "    # Create a new column 'last_state' where the last session was recorded\n",
    "    df = df.withColumn(\"state\", substring(df.location, -2, 2))\n",
    "    df = df.withColumn('last_state', when(df_last_ts.last_interaction == df.ts_date, df.state))\n",
    "        \n",
    "    # Compute average songs played by day per user\n",
    "    w = Window.partitionBy('userId', 'date')\n",
    "    songs = df.where(df.page == 'NextSong').select('userId', 'date', count('userId').over(w).alias('songs')).distinct()\n",
    "    w = Window.partitionBy('userId')\n",
    "    songs = songs.withColumn('avg_songs_per_day', avg('songs').over(w))\n",
    "    songs = songs.select(songs['userId'].alias('songs_userId'), 'avg_songs_per_day')\n",
    "    songs = songs.withColumn('avg_songs_per_day', F.round(songs['avg_songs_per_day'],2)).distinct()\n",
    "    \n",
    "    # Compute the number of thumbs up for user\n",
    "    w = Window.partitionBy('userId')\n",
    "    thumbs_up = df.where(df.page == 'Thumbs Up').select('userId', count('userId').over(w).alias('thumbs_up')).distinct()\n",
    "    thumbs_up = thumbs_up.select(thumbs_up['userId'].alias('thumbsup_userId'), 'thumbs_up')\n",
    " \n",
    "    # Compute the number of thumbs down per user\n",
    "    w = Window.partitionBy('userId')\n",
    "    thumbs_down = df.where(df.page == 'Thumbs Down').select('userId', count('userId').over(w).alias('thumbs_down')).distinct()\n",
    "    thumbs_down = thumbs_down.select(thumbs_down['userId'].alias('thumbsdown_userId'), 'thumbs_down')\n",
    "      \n",
    "    # Compute the number of add friend events per user\n",
    "    w = Window.partitionBy('userId')\n",
    "    num_add_friend = df.where(df.page == 'Add Friend').select('userId', count('userId').over(w).alias('num_add_friend')).distinct()\n",
    "    num_add_friend = num_add_friend.select(num_add_friend['userId'].alias('friends_userId'), 'num_add_friend')\n",
    "    \n",
    "    # Compute the fraction of page 'roll advert'\n",
    "    w = Window.partitionBy('userId', 'date')\n",
    "    roll_adv = df.where(df.page == 'Roll Advert').select('userId', 'date', count('userId').over(w).alias('roll_adv')).distinct()\n",
    "    w = Window.partitionBy('userId')\n",
    "    roll_adv = roll_adv.withColumn('avg_roll_adv_per_day', avg('roll_adv').over(w))\n",
    "    roll_adv = roll_adv.select(roll_adv['userId'].alias('rolladv_userId'), 'avg_roll_adv_per_day')\n",
    "    roll_adv = roll_adv.withColumn('avg_roll_adv_per_day', F.round(roll_adv['avg_roll_adv_per_day'],2)).distinct()\n",
    "    \n",
    "    # Construct the final dataset\n",
    "    df_ml = df.select('userId', 'gender', 'churn_cancellation', 'days_registered', 'last_state').dropna().drop_duplicates()\n",
    "    df_ml = df_ml.join(songs, df_ml.userId == songs.songs_userId, how='left').distinct() \n",
    "    df_ml = df_ml.join(levels, df_ml.userId == levels.level_userId, how='left').distinct()\n",
    "    df_ml = df_ml.join(thumbs_up, df_ml.userId == thumbs_up.thumbsup_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['thumbs_up'])\n",
    "    df_ml = df_ml.join(thumbs_down, df_ml.userId == thumbs_down.thumbsdown_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['thumbs_down'])\n",
    "    df_ml = df_ml.withColumn('Thumbsup_proportion', F.round(df_ml.thumbs_up / df_ml.thumbs_down, 2))\n",
    "    df_ml = df_ml.fillna(0, subset=['Thumbsup_proportion'])\n",
    "    df_ml = df_ml.join(num_add_friend, df_ml.userId == num_add_friend.friends_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['num_add_friend'])\n",
    "    df_ml = df_ml.join(roll_adv, df_ml.userId == roll_adv.rolladv_userId, how='left').distinct()\n",
    "    df_ml = df_ml.fillna(0, subset=['avg_roll_adv_per_day'])\n",
    "    df_ml = df_ml.drop('thumbs_up', 'thumbs_down', 'songs_userId', 'level_userID', 'rolladv_userId', 'thumbsup_userId', 'thumbsdown_userId', 'friends_userId')\n",
    "\n",
    "    return df_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359b6c8-ecc8-4655-a0f3-832cb57ef10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = prepare_dataset(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9dc2e-1ffc-4cfb-9651-19401cef1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_pandas = df_ml.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c025b-3ea0-489d-a9ea-ecff261f30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_pandas.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27dcbc-3360-4225-9287-cd0a310f45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698e077-5d83-4111-ad47-4234b554e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_pandas.churn_cancellation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb279a1-56b4-4c1f-a43b-48034cfc4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation with the target variable 'churn_cancellation'\n",
    "df_ml_pandas.corr()['churn_cancellation'].abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696cc98-2809-4bdb-9e46-ec5eb565baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation among features\n",
    "\n",
    "# creating mask\n",
    "mask = np.triu(np.ones_like(df_ml_pandas.corr()))\n",
    " \n",
    "# plotting a triangle correlation heatmap\n",
    "dataplot = sns.heatmap(df_ml_pandas.corr(), cmap=\"YlGnBu\", annot=True, mask=mask)\n",
    "\n",
    "# displaying heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e1bc2-b26c-43cc-ae62-87743813073e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e351d-5a75-43fd-ad18-fe4547f4f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluator User Defined Functions\n",
    "def udfModelEvaluator(dfPredictions, labelColumn='label'):\n",
    "\n",
    "    colSelect = dfPredictions.select(\n",
    "      [F.col('prediction').cast(DoubleType())\n",
    "       ,F.col(labelColumn).cast(DoubleType()).alias('label')])\n",
    "\n",
    "    metrics = MulticlassMetrics(colSelect.rdd)\n",
    "\n",
    "    mMatrix = metrics.confusionMatrix().toArray().astype(int)    \n",
    "\n",
    "    mTP = metrics.confusionMatrix().toArray()[1][1]\n",
    "    mTN = metrics.confusionMatrix().toArray()[0][0]\n",
    "    mFP = metrics.confusionMatrix().toArray()[0][1]\n",
    "    mFN = metrics.confusionMatrix().toArray()[1][0]\n",
    "    \n",
    "    mAccuracy = metrics.accuracy\n",
    "    mPrecision = mTP / (mTP + mFP)\n",
    "    mRecall = mTP / (mTP + mFN)\n",
    "    mF1 = metrics.fMeasure(1.0)\n",
    "\n",
    "    mResults = [mAccuracy, mPrecision, mRecall, mF1, mMatrix, mTP, mTN, mFP, mFN, \"Return [[0]=Accuracy, [1]=Precision, [2]=Recall, [3]=F1, [4]=ConfusionMatrix, [5]=TP, [6]=TN, [7]=FP, [8]=FN]\"]\n",
    "\n",
    "    return mResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd17d7-a7ba-4106-843e-648e29635fbe",
   "metadata": {},
   "source": [
    "### Split into Train, Test and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61605d-d23a-4a5f-bc42-1a12114f19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets (80% - 20%)\n",
    "\n",
    "df_ml = df_ml.withColumnRenamed(\"churn_cancellation\", \"label\")\n",
    "\n",
    "train, test = df_ml.randomSplit([0.8, 0.2], seed = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b927ed-d382-49de-9137-77ac2c400210",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_train = train.groupBy('label').count().toPandas()\n",
    "print(counts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d4445-c5f3-43f5-b909-c5b5eb5a11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts\n",
    "count_churned = counts_train[counts_train['label']==1]['count'].values[0]\n",
    "count_total = counts_train['count'].sum()\n",
    "\n",
    "# Weights\n",
    "c = 2\n",
    "weight_churned = count_total / (c * count_churned)\n",
    "weight_no_churned = count_total / (c * (count_total - count_churned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4389b86-bb70-44ed-b6f8-de24e9bee8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn(\"weight\", when(train.label ==1, weight_churned).otherwise(weight_no_churned))\n",
    "train.select('label', 'weight').where(train.label ==1).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc69ee-d17a-4441-8ce5-9f5922498dd0",
   "metadata": {},
   "source": [
    "### Machine Learning Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74416be-35f3-4e41-b92a-5d714340884c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StringIndexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8r/0dc1hj493qndcp189v0654jc0000gp/T/ipykernel_19756/2932748622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Index and encode categorical feature 'last_state'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m stringIndexerState = StringIndexer(inputCol=\"last_state\", \n\u001b[0m\u001b[1;32m      3\u001b[0m                                    outputCol=\"stateIndex\")\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m encoder = OneHotEncoder(inputCols=[\"stateIndex\"],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StringIndexer' is not defined"
     ]
    }
   ],
   "source": [
    "# Index and encode categorical feature 'last_state'\n",
    "stringIndexerState = StringIndexer(inputCol=\"last_state\", \n",
    "                                   outputCol=\"stateIndex\")\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"stateIndex\",\n",
    "                        outputCol=\"stateVec\")\n",
    "\n",
    "# Create a vector for features to be used in the models\n",
    "features = ['stateVec', 'gender', 'days_registered', 'avg_songs_per_day', 'last_level', 'Thumbsup_proportion', 'num_add_friend', 'avg_roll_adv_per_day']\n",
    "\n",
    "# Merge multiple columns into a vector column\n",
    "assemblers = VectorAssembler(inputCols=features, outputCol=\"rawFeatures\", handleInvalid = \"keep\")\n",
    "\n",
    "# Scale features\n",
    "scalers = MinMaxScaler(inputCol=\"rawFeatures\", outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609d70c-bdb9-4ad6-86ee-fac4904b7a90",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c4589-8e02-47c1-ac6b-2228a0fe6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression Classifier\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Assemble pipeline\n",
    "pipeline_lr = Pipeline(stages=[stringIndexerState, encoder, assemblers, scalers, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188f71a-8ad7-4035-8450-233523530ca4",
   "metadata": {},
   "source": [
    "#### Cross Validation and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df392052-ff0a-4fe6-ac97-ec2baabf9355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [10, 30, 50]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.3]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.8])\\\n",
    "    .addGrid(lr.family, ['auto'])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b287de0-f717-4fb8-9a71-dcaa07328eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_lr = CrossValidator(estimator=pipeline_lr,\n",
    "                          estimatorParamMaps=paramGrid_lr,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c30584-6035-40a6-ae55-567920f578ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel_lr = crossval_lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1631108-383d-48be-8518-120546551586",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel_lr = cvModel_lr.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11e290-eb0b-45b4-adf6-2d2498312faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_best_lr = bestModel_lr.transform(train)\n",
    "pred_test_best_lr = bestModel_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bce0bd-4350-4187-a0f3-bc957b111d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = pred_train_best_lr.rdd.map(lambda lp: (float(lp.prediction), float(lp.label))).toDF().withColumnRenamed('_1', 'prediction').withColumnRenamed('_2', 'label')\n",
    "metricsList_train_best_lr = udfModelEvaluator(predictionAndLabels, \"label\")\n",
    "\n",
    "print('Metrics Train set:')\n",
    "print(' ')\n",
    "print(f'Accuracy: {metricsList_train_best_lr[0]}')\n",
    "print(f'Precision: {metricsList_train_best_lr[1]}')\n",
    "print(f'Recall: {metricsList_train_best_lr[2]}')\n",
    "print(f'F1-score: {metricsList_train_best_lr[3]}')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83352d-b680-41b2-9c0c-913893f6ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metricsList_train_best_lr[4], annot=True, fmt='g', cmap='Blues', ax=ax)\n",
    "ax.xaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.yaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcd8c8-68fb-48fa-b755-b1c5b2ec25ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = pred_test_best_lr.rdd.map(lambda lp: (float(lp.prediction), float(lp.label))).toDF().withColumnRenamed('_1', 'prediction').withColumnRenamed('_2', 'label')\n",
    "metricsList_test_best_lr = udfModelEvaluator(predictionAndLabels, \"label\")\n",
    "\n",
    "print('Metrics Test set:')\n",
    "print(' ')\n",
    "print(f'Accuracy: {metricsList_test_best_lr[0]}')\n",
    "print(f'Precision: {metricsList_test_best_lr[1]}')\n",
    "print(f'Recall: {metricsList_test_best_lr[2]}')\n",
    "print(f'F1-score: {metricsList_test_best_lr[3]}')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cead0-3af1-47b1-866e-71c7a0377cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metricsList_test_best_lr[4], annot=True, fmt='g', cmap='Blues', ax=ax)\n",
    "ax.xaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.yaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd86455-abb1-44de-9a57-ab837f8e08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of cross validation\n",
    "\n",
    "# get parameters\n",
    "params = [{p.name: v for p, v in m.items()} for m in cvModel_lr.getEstimatorParamMaps()]\n",
    "\n",
    "# Convert validation results to pandas dataframe\n",
    "validation_results_lr = pd.DataFrame.from_dict([\n",
    "    {cvModel_lr.getEvaluator().getMetricName(): metric, **ps} \n",
    "    for ps, metric in zip(params, cvModel_lr.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3699c9-ea2a-4fcd-8865-9c2138525d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3275604-da07-4b33-86df-0481460f9e66",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb73167-6cc3-4b11-a292-e036dc5e348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Assemble pipeline\n",
    "pipeline_rf = Pipeline(stages=[stringIndexerState, encoder, assemblers, scalers, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63a19f-bd5c-4705-9014-b80e615493e2",
   "metadata": {},
   "source": [
    "#### Cross Validation and Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6cca5-f91f-4956-8c10-fb22e30a0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
    "    .addGrid(rf.maxDepth, [3, 4, 5]) \\\n",
    "    .addGrid(rf.impurity, ['entropy', 'gini'])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5f395-3c95-4467-880a-57853c29d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_rf = CrossValidator(estimator=pipeline_rf,\n",
    "                          estimatorParamMaps=paramGrid_rf,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890307c6-51f0-4aac-addd-1fe13014486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel_rf = crossval_rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311a5ab-5823-4d14-a124-0c3b918ad0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel_rf = cvModel_rf.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdc68e-dce6-463d-acb1-f2966c1ced73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_best_rf = bestModel_rf.transform(train)\n",
    "pred_test_best_rf = bestModel_rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d3423-cc48-4fba-82ed-30c391dfb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = pred_train_best_rf.rdd.map(lambda lp: (float(lp.prediction), float(lp.label))).toDF().withColumnRenamed('_1', 'prediction').withColumnRenamed('_2', 'label')\n",
    "metricsList_train_best_rf = udfModelEvaluator(predictionAndLabels, \"label\")\n",
    "\n",
    "print('Metrics Train set:')\n",
    "print(' ')\n",
    "print(f'Accuracy: {metricsList_train_best_rf[0]}')\n",
    "print(f'Precision: {metricsList_train_best_rf[1]}')\n",
    "print(f'Recall: {metricsList_train_best_rf[2]}')\n",
    "print(f'F1-score: {metricsList_train_best_rf[3]}')\n",
    "print(' ')\n",
    "\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metricsList_train_best_rf[4], annot=True, fmt='g', cmap='Blues', ax=ax)\n",
    "ax.xaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.yaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bade54-3f50-4ae3-8166-891888af267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = pred_test_best_rf.rdd.map(lambda lp: (float(lp.prediction), float(lp.label))).toDF().withColumnRenamed('_1', 'prediction').withColumnRenamed('_2', 'label')\n",
    "metricsList_test_best_rf = udfModelEvaluator(predictionAndLabels, \"label\")\n",
    "\n",
    "print('Metrics Test set:')\n",
    "print(' ')\n",
    "print(f'Accuracy: {metricsList_test_best_rf[0]}')\n",
    "print(f'Precision: {metricsList_test_best_rf[1]}')\n",
    "print(f'Recall: {metricsList_test_best_rf[2]}')\n",
    "print(f'F1-score: {metricsList_test_best_rf[3]}')\n",
    "print(' ')\n",
    "\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metricsList_test_best_rf[4], annot=True, fmt='g', cmap='Blues', ax=ax)\n",
    "ax.xaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.yaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3a31b-9ad9-48ca-b498-009f8ecd8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = bestModel_rf.stages[4]\n",
    "importances = bestModel.featureImportances.toArray()\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Retrieve features' labels\n",
    "features_sel = ['gender', 'days_registered', 'avg_songs_per_day', 'last_level', 'Thumbsup_proportion', 'num_add_friend', 'avg_roll_adv_per_day']\n",
    "features_states = bestModel_rf.stages[0].labels\n",
    "features_labels = features_states + features_sel\n",
    "feature_coef_df = pd.DataFrame(list(zip(features_labels, importances)), columns=['Feature', 'Importance'])\\\n",
    "    .sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance of the best model\n",
    "plt.figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_coef_df, orient = 'h')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e199beb-e85a-4ff3-b929-249a6fef629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the parameters of the best model\n",
    "bestModel = bestModel_rf.stages[4]\n",
    "print('numTrees - ', bestModel.getNumTrees)\n",
    "print('maxDepth - ', bestModel.getOrDefault('maxDepth'))\n",
    "print('impurity - ', bestModel.getOrDefault('impurity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900444eb-2869-43ba-a15d-3afaf525043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of cross validation\n",
    "\n",
    "# get parameters\n",
    "params = [{p.name: v for p, v in m.items()} for m in cvModel_rf.getEstimatorParamMaps()]\n",
    "\n",
    "# Convert validation results to pandas dataframe\n",
    "validation_results_rf = pd.DataFrame.from_dict([\n",
    "    {cvModel_rf.getEvaluator().getMetricName(): metric, **ps} \n",
    "    for ps, metric in zip(params, cvModel_rf.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572faa4-3566-48b3-bfbc-edf3e009dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a6414-0ef5-4780-a085-0adea7294f24",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c3cfd-a818-4ea5-b774-332b20bd927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gradient-Boosting Tree Classifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Assemble pipeline\n",
    "pipeline_gbt = Pipeline(stages = [stringIndexerState, encoder, assemblers, scalers, gbt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211551db-9572-44e7-9b36-5c1a89359e3b",
   "metadata": {},
   "source": [
    "#### Cross Validation and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c13e77-6f73-41fd-a8ab-4a44da9b9766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [10, 20, 40]) \\\n",
    "    .addGrid(gbt.maxDepth, [2, 3, 5]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4be1a-e712-4061-9c5c-00250f1fd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_gbt = CrossValidator(estimator=pipeline_gbt,\n",
    "                          estimatorParamMaps=paramGrid_gbt,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17439c-99e6-4632-ad59-3cabae7bfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel_gbt = crossval_gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695304f-06ef-4d75-94dc-6f3b4b962196",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel_gbt = cvModel_gbt.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba821dc-a62e-4bfd-aded-2698b5957cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_best_gbt = bestModel_gbt.transform(train)\n",
    "pred_test_best_gbt = bestModel_gbt.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dcd308-aca2-4ecd-b91a-f0207cf13ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = pred_train_best_gbt.rdd.map(lambda lp: (float(lp.prediction), float(lp.label))).toDF().withColumnRenamed('_1', 'prediction').withColumnRenamed('_2', 'label')\n",
    "metricsList_train_best_gbt = udfModelEvaluator(predictionAndLabels, \"label\")\n",
    "metricsList_train_best_gbt\n",
    "\n",
    "print('Metrics Train set:')\n",
    "print(' ')\n",
    "print(f'Accuracy: {metricsList_train_best_gbt[0]}')\n",
    "print(f'Precision: {metricsList_train_best_gbt[1]}')\n",
    "print(f'Recall: {metricsList_train_best_gbt[2]}')\n",
    "print(f'F1-score: {metricsList_train_best_gbt[3]}')\n",
    "print(' ')\n",
    "\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metricsList_train_best_gbt[4], annot=True, fmt='g', cmap='Blues', ax=ax)\n",
    "ax.xaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.yaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179aefd-9118-4764-ade3-5048774079e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = pred_test_best_gbt.rdd.map(lambda lp: (float(lp.prediction), float(lp.label))).toDF().withColumnRenamed('_1', 'prediction').withColumnRenamed('_2', 'label')\n",
    "metricsList_test_best_gbt = udfModelEvaluator(predictionAndLabels, \"label\")\n",
    "metricsList_test_best_gbt\n",
    "\n",
    "print('Metrics Test set:')\n",
    "print(' ')\n",
    "print(f'Accuracy: {metricsList_test_best_gbt[0]}')\n",
    "print(f'Precision: {metricsList_test_best_gbt[1]}')\n",
    "print(f'Recall: {metricsList_test_best_gbt[2]}')\n",
    "print(f'F1-score: {metricsList_test_best_gbt[3]}')\n",
    "print(' ')\n",
    "\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metricsList_test_best_gbt[4], annot=True, fmt='g', cmap='Blues', ax=ax)\n",
    "ax.xaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.yaxis.set_ticklabels(['Not Churned', 'Churned'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a8f0e-074d-4ddf-a525-659c944f248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = bestModel_gbt.stages[4]\n",
    "importances = bestModel.featureImportances.toArray()\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Retrieve features'| labels\n",
    "features_sel = ['gender', 'days_registered', 'avg_songs_per_day', 'last_level', 'Thumbsup_proportion', 'num_add_friend', 'avg_roll_adv_per_day']\n",
    "features_states = bestModel_gbt.stages[0].labels\n",
    "features_labels = features_states + features_sel\n",
    "feature_coef_df = pd.DataFrame(list(zip(features_labels, importances)), columns=['Feature', 'Importance'])\\\n",
    "    .sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance of the best model\n",
    "plt.figure(figsize=(10, 8), dpi=80)\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_coef_df, orient = 'h')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404d307-8a7f-4236-ae21-6fc913ea6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of cross validation\n",
    "\n",
    "# get parameters\n",
    "params = [{p.name: v for p, v in m.items()} for m in cvModel_gbt.getEstimatorParamMaps()]\n",
    "\n",
    "# Convert validation results to pandas dataframe\n",
    "validation_results_gbt = pd.DataFrame.from_dict([\n",
    "    {cvModel_gbt.getEvaluator().getMetricName(): metric, **ps} \n",
    "    for ps, metric in zip(params, cvModel_gbt.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2815daa-bfea-4f5e-b769-1013ce9e755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results_gbt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02edac0c-c98b-486e-9508-c27422f93d90",
   "metadata": {},
   "source": [
    "## Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6104633-b2e1-4f77-a6aa-9aca4fb93403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the results of F1 score for each model in a dataframe\n",
    "res = [{'Classifier': 'Logistic Regression', 'Train - F1 score': metricsList_train_best_lr[3], 'Test - F1 score': metricsList_test_best_lr[3]},\n",
    "       {'Classifier': 'Random Forest', 'Train - F1 score': metricsList_train_best_rf[3], 'Test - F1 score': metricsList_test_best_rf[3]},\n",
    "       {'Classifier': 'Gradient-boosted Tree', 'Train - F1 score': metricsList_train_best_gbt[3], 'Test - F1 score': metricsList_test_best_gbt[3]}]\n",
    "\n",
    "results = pd.DataFrame(res)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e1ef3-fe28-4924-a53f-edd0551b25bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79673a-fca3-48b0-9009-2c8ec8723122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127d460-703d-4b03-8125-59ae959180fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
